{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 250645,
          "sourceType": "datasetVersion",
          "datasetId": 105271
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SushankReddyNallu/Msc-project/blob/main/deepfakedetectionshushankr1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-13T09:04:29.008159Z",
          "iopub.execute_input": "2024-05-13T09:04:29.008522Z",
          "iopub.status.idle": "2024-05-13T09:04:30.212041Z",
          "shell.execute_reply.started": "2024-05-13T09:04:29.008491Z",
          "shell.execute_reply": "2024-05-13T09:04:30.210999Z"
        },
        "trusted": true,
        "id": "oXmoJmH2NxAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "owT_aeZTNxAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZuEkNw8Nz0j",
        "outputId": "1e3379af-ca88-4c31-f660-645a74a2849a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define paths to the dataset\n",
        "train_dir = '/content/drive/MyDrive/real_and_fake_face'\n",
        "\n",
        "train_fake_dir = os.path.join(train_dir, 'training_fake')\n",
        "train_real_dir = os.path.join(train_dir, 'training_real')\n",
        "\n",
        "#test_dir = os.path.join(train_dir, 'testing')\n",
        "\n",
        "# Define image dimensions and batch size\n",
        "img_width, img_height = 250, 250\n",
        "batch_size = 32\n",
        "\n",
        "# Preprocess and augment the training images\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# Preprocess the test images (only rescaling)\n",
        "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generate batches of augmented data for training and validation\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    color_mode = \"rgb\",\n",
        "    batch_size=batch_size,\n",
        "    class_mode = \"categorical\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T09:04:39.091965Z",
          "iopub.execute_input": "2024-05-13T09:04:39.092448Z",
          "iopub.status.idle": "2024-05-13T09:04:54.914700Z",
          "shell.execute_reply.started": "2024-05-13T09:04:39.092420Z",
          "shell.execute_reply": "2024-05-13T09:04:54.913777Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bCGeTufNxAl",
        "outputId": "1fcc8d85-6822-477b-8d26-c07e16847516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2051 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These commands are typically used at the command line or in a notebook cell with ! prefix\n",
        "!pip install tensorflow\n",
        "# !pip install numpy\n",
        "# !pip install pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK4SkmYQOvJB",
        "outputId": "bcd5effe-a0fc-4dab-992f-56d6d3bf950f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers\n",
        "import keras.backend as K\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_initializer='glorot_uniform', **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "        self.W = self.add_weight(shape=[self.input_num_capsule, self.num_capsule, self.input_dim_capsule, self.dim_capsule],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "\n",
        "        inputs_expand = tf.expand_dims(inputs, 1)\n",
        "\n",
        "        inputs_tiled = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
        "\n",
        "        inputs_hat = tf.map_fn(lambda x: K.batch_dot(x, self.W, [2, 3]), elems=inputs_tiled)\n",
        "\n",
        "        b = tf.zeros(shape=[tf.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule])\n",
        "\n",
        "        assert self.routings > 0, 'The routings should be > 0.'\n",
        "        for i in range(self.routings):\n",
        "            c = tf.nn.softmax(b, dim=1)\n",
        "\n",
        "            outputs = squash(tf.batch_dot(c, inputs_hat, [2, 2]))  # [None, 10, 16]\n",
        "\n",
        "            if i < self.routings - 1:\n",
        "                b += tf.batch_dot(outputs, inputs_hat, [2, 3])\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
        "\n",
        "\n",
        "# Define the Capsule Network model\n",
        "def CapsuleNet(input_shape, num_classes, routings):\n",
        "    x = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Layer 1: Convolutional layer\n",
        "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "\n",
        "    # Layer 2: Primary Capsule Layer\n",
        "    primary_capsules = layers.Conv2D(filters=256, kernel_size=9, strides=2, padding='valid', activation='relu',\n",
        "                                     name='primary_capsules')(conv1)\n",
        "\n",
        "    # Layer 3: Capsule Layer\n",
        "   # digit_capsule = CapsuleLayer(num_capsule=num_classes, dim_capsule=16, routings=routings, name='digit_capsule')(primary_capsules)\n",
        "\n",
        "\n",
        "\n",
        "    # Flatten the Capsules\n",
        "    out_caps = layers.Flatten()(primary_capsules)\n",
        "\n",
        "    # Output layer\n",
        "    output = layers.Dense(2, activation='sigmoid')(out_caps)\n",
        "\n",
        "    # Define the model\n",
        "    model = models.Model(inputs=x, outputs=output, name='CapsuleNet')\n",
        "    return model\n",
        "\n",
        "# Build Capsule Network model\n",
        "model = CapsuleNet(input_shape=(250, 250, 3), num_classes=2, routings=3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "do_xNHXLsEwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building and training"
      ],
      "metadata": {
        "id": "ahnZotm7NxAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T09:05:05.722289Z",
          "iopub.execute_input": "2024-05-13T09:05:05.723028Z",
          "iopub.status.idle": "2024-05-13T09:05:05.745670Z",
          "shell.execute_reply.started": "2024-05-13T09:05:05.722993Z",
          "shell.execute_reply": "2024-05-13T09:05:05.744791Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRheruLNNxAn",
        "outputId": "7dc81985-9665-4a60-acd0-6c64c126b9ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"CapsuleNet\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 250, 250, 3)]     0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 242, 242, 256)     62464     \n",
            "                                                                 \n",
            " primary_capsules (Conv2D)   (None, 117, 117, 256)     5308672   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 3504384)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 7008770   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12379906 (47.23 MB)\n",
            "Trainable params: 12379906 (47.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=50\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T09:05:09.635068Z",
          "iopub.execute_input": "2024-05-13T09:05:09.635512Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WO-YST_NxAn",
        "outputId": "86531797-dd27-4009-8a32-eb0b7e70647a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "64/64 [==============================] - 16015s 250s/step - loss: 8.4336 - accuracy: 0.5201\n",
            "Epoch 2/50\n",
            " 8/64 [==>...........................] - ETA: 3:57:22 - loss: 0.6932 - accuracy: 0.4961"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting training and validation loss and accuracy curves"
      ],
      "metadata": {
        "id": "EWQu8bsBNxAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "epochs = 50\n",
        "\n",
        "# Generate epochs array\n",
        "epochs_array = np.arange(1, epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs_array, history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.plot(epochs_array, history.history['val_loss'], label='Validation Loss', color='orange')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(np.arange(0, epochs + 1, 5))  # Customize x-axis ticks\n",
        "plt.yticks(np.arange(0, initial_loss + 0.1, 0.1))  # Customize y-axis ticks\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NJ-PLe5-NxAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs_array, history.history['accuracy'], label='Training accuracy', color='blue')\n",
        "plt.plot(epochs_array, history.history['val_accuracy'], label='Validation accuracy', color='orange')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(np.arange(0, epochs + 1, 5))  # Customize x-axis ticks\n",
        "plt.yticks(np.arange(0, initial_loss + 0.1, 0.1))  # Customize y-axis ticks\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kdyhA9S6NxAn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}